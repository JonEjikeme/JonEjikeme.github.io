<h1 id="cluster-server">Cluster Server</h1>

<p><img src="/assets/img/portfolio/cluster/Cluster.png" alt="Cluster Server" /></p>

<p>In information technology, redundancy is crucial for ensuring system reliability. By eliminating single points of failure, it enhances overall system stability. We’ve all experienced the frustration of trying to access an unavailable system—especially when it’s needed most. For large organizations, unexpected downtime can result in significant financial and operational consequences.
For this project, I set out to gain hands-on experience in building highly available systems on a smaller scale. Using Docker Swarm and a cluster of Raspberry Pis, I created a highly available server to explore the principles of redundancy and fault tolerance.</p>

<h2 id="why-docker-swarm">Why Docker Swarm</h2>

<p>Previously, I used my Raspberry Pi to run Docker containers, including Pi-hole [(LINK TO PIHOLE)]. While researching highly available container orchestration solutions, I explored both Docker Swarm and Kubernetes. Kubernetes, with its complexity and extensive customization options, is well-suited for large, intricate systems. However, for my use case, it felt like overkill. Instead, I opted for Docker Swarm due to its simplicity and ease of use, making it a better fit for small-scale environments.</p>

<h2 id="hardware">Hardware</h2>

<p>Having a history of tinkering with Raspberry Pis, I decided to use them for my cluster. I already owned three, so I only needed to purchase one more to complete the setup. Raspberry Pis are low-power devices, making them ideal for always-on systems, especially when handling lightweight workloads. Another reason for choosing the Raspberry Pi is its strong community of enthusiasts, who provide a wealth of resources and support.
For my cluster, I used this case [(LINK TO RPI CASE)], which offers ample space for proper ventilation. To enable communication between the systems, they needed to be connected through a switch, so I used a 4-port switch for the setup.</p>

<h2 id="system-setup">System Setup</h2>

<p>One of the most satisfying parts of this project was assembling the system. I wanted a setup where a single power connection would bring everything online seamlessly. To achieve this, I used a 65W power supply and USB power cables for the Raspberry Pis.
Ethernet switches typically come with a standard socket plug, but since I wanted to power the entire system from a single source, I modified the switch’s power connection. I cut off the socket plug from its 5V power cable and soldered it to a USB port, allowing me to power the switch via a power bank. This way, the entire cluster required only one cable from the power bank to stay operational.
For the operating system, I chose Raspberry Pi OS, which is based on Debian Linux. It is reliable, open-source, and well-optimized for Raspberry Pi hardware. I also used SD cards as the primary storage, as they can last for years before needing replacement.</p>

<h2 id="setting-up-docker-swarm">Setting up Docker Swarm</h2>

<p>This was by far the easiest part of the project, as the initial setup required only two commands.</p>

<p>On the master node, we run:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker swarm init
</code></pre></div></div>

<p>After running this we are given a token that allows us to add other nodes.</p>

<p>On the other nodes we run:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker swarm join --token &lt;token&gt; &lt;manager_node_ip&gt;:2377
</code></pre></div></div>

<p>With just these commands, the cluster is up and running.</p>

<h2 id="security">Security</h2>

<p>Cybersecurity is a multifaceted endeavor—securing a system requires vigilance at every level. The best approach depends on the system’s specific implementation, with various strategies to consider. Below are some of the key security configurations I implemented for the Raspberry Pi system.</p>

<h3 id="require-root-password">Require Root Password</h3>

<p>When I first configured a Raspberry Pi system, I was surprised to find that it does not require a root password for sudo commands. As security practitioners, we recognize this as a significant security risk—any user with access to the system can easily escalate their privileges. Since the Raspberry Pi is designed to be beginner-friendly, I assume this decision was made to simplify usability.
However, for security reasons, I changed this default behavior. To do so, I modified the sudoers configuration by navigating to the /etc/sudoers.d directory and changing the line:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pi ALL=(ALL) NOPASSWD: ALL 
</code></pre></div></div>
<p>To</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pi ALL=(ALL) ALL
</code></pre></div></div>

<h3 id="ssh-config">SSH Config</h3>

<p>The next change I made was to the sshd_config file, as SSH is my primary method of connecting to these systems. To enhance security, I enabled key-based authentication, which is generally more secure than password-based access.
I also changed the default SSH listening port. While I don’t expose SSH ports to the internet—since doing so invites unnecessary automated attacks—I still take this precaution on any system where SSH is enabled. Instead of exposing SSH directly, I use a VPN tunnel to establish a secure connection to the system.</p>

<h3 id="sysctlconf">Sysctl.conf</h3>

<p>Whenever I configure a Linux server, I always review the /etc/sysctl.conf file, which contains kernel and networking parameters. Some of the key changes I made include disabling IPv6, disabling ICMP echo and broadcasts, enabling tcp_syncookies to mitigate SYN flood DDoS attacks, and applying several other security and performance optimizations.
This file offers a wide range of configurable options, allowing for fine-tuned adjustments to enhance both security and system performance.</p>

<h2 id="nfs-server">NFS Server</h2>

<p>To share configuration files across all nodes in the cluster, I decided to implement a Network File System (NFS) server. NFS is a protocol that enables file sharing between computers, similar to the SMB protocol in Windows. In this setup, the NFS server is hosted on the second node.
I also utilized AutoFS, a program that automatically mounts file systems when accessed and can be configured to unmount them after a specified period of inactivity. This feature helps mitigate potential issues related to improper mounting of the file system.</p>

<h2 id="conclusion">Conclusion</h2>

<p>This project has been an invaluable learning experience. It has allowed me to deepen my understanding of high availability systems, redundancy, and fault tolerance. The simplicity of Docker Swarm suited my small-scale environment perfectly, while the Raspberry Pi provided an accessible and powerful platform for experimentation. Moving forward, I feel more confident in applying these principles to larger, more complex systems, andI look forward to expanding the number of services I will run on the cluster.</p>
